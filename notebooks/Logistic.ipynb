{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘½ðŸ‘¾ Sci-fi IRL #2: PrintSF ðŸ“šðŸ›¸\n",
    "\n",
    "#### A Predictive Machine Learning Model by Tobias Reaper\n",
    "\n",
    "#### ---- Datalogue 02-009-01 ----\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. Intro\n",
    "2. Predict\n",
    "  - Can use a \"star\" component if predicting\n",
    "3. Explain / Insights / Analysis\n",
    "  - Methodology\n",
    "  - Choice of features\n",
    "  - Feature engineering\n",
    "  - Choice of model\n",
    "  - Choice of metrics\n",
    "4. Process\n",
    "  - Size of data\n",
    "  - Cross-Validation method + train / test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TODOjo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Hygiene\n",
    "\n",
    "- [x] Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling\n",
    "\n",
    "- [x] Get accuracy score for majority class baseline\n",
    "- [x] Get baseline accuracy score for basic logistic regression\n",
    "- [ ] Beat baseline with gradient-boosted classification model\n",
    "- [ ] Use RandomizedSearchCV to tune hyperparameters (LSDS_223)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation\n",
    "\n",
    "- [ ] Feature Importances\n",
    "- [ ] Permutation Importances (LSDS 232)\n",
    "- [ ] Partial Dependencies\n",
    "- [ ] Get and interpret confusion matrix (LSDS_224) + precision / recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Imports and Configuration\n",
    "\n",
    "ðŸ“¥âš™ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Utiliteers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extrateers\n",
    "import seaborn as sns\n",
    "import janitor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly imports\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly\"  # Set to dark mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter + Plotly imports (if running in Colab or Visual Studio Code, comment out this cell)\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()  # Set plotly to notebook mode / work offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore this Numpy warning when using Plotly Express:\n",
    "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas display options to allow for more columns and rows\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Infrastructure\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Crunchy\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### LowData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to current session directory - 009\n",
    "datapath = \"/Users/Tobias/workshop/dasci/projects/thepurpledot_dev/stories/sci_fi_irl-02/009-Session/\"\n",
    "\n",
    "# Create path to the books dataset\n",
    "filename = \"must_read_books_008-03.csv\"\n",
    "\n",
    "filepath = os.path.join(datapath, filename)\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: chain up the initial encodings and data rassling\n",
    "\n",
    "# Load the data\n",
    "df1 = pd.read_csv(filepath)\n",
    "\n",
    "# Simple numerical encoding of Bool\n",
    "df2 = df1.replace(to_replace={True: 1, False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interaction Features\n",
    "  - [ ] `fiction` | `short_stories`\n",
    "  - [ ] `fiction` & `short_stories`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Interaction Features, Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pyjanitor's `update_where()` once again, this time for an &\n",
    "df8 = (df7\n",
    "       .update_where(\n",
    "           conditions=((df7[\"fiction\"] == 1) & \n",
    "                      (df7[\"short_stories\"] == 1)),\n",
    "           target_column_name=\"overlap\",\n",
    "           target_val=1,\n",
    "       )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8[\"overlap\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out if \"short_stories\" is leaky\n",
    "df7_f1 = df7[(df7[\"fiction\"] == 0) & (df7[\"short_stories\"] == 1)]\n",
    "df7_f1.shape\n",
    "# Verdict is it doesn't look leaky to me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Posterity Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the current dataframe to file\n",
    "# df2.to_csv(\"must_read_books_008-03.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find outliers in numerical features, utilize boxplot\n",
    "sns.boxplot(x=df2[\"num_pages\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how much removing pages outliers affects dataset\n",
    "# This could even be one of the sliders on the app\n",
    "cutoff = 1000\n",
    "df3 = df2[df2[\"num_pages\"] <= cutoff]\n",
    "print(f\"There are {df2.shape[0] - df3.shape[0]} books above {cutoff} pages long.\")\n",
    "print(f\"The resulting dataset has {df3.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find outliers in numerical features, utilize boxplot\n",
    "sns.boxplot(x=df3[\"num_ratings\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how much removing ratings outliers affects dataset\n",
    "cutoff = 1000000\n",
    "df4 = df3[df3[\"num_ratings\"] <= cutoff]\n",
    "print(f\"There are {df3.shape[0] - df4.shape[0]} books with above {cutoff} ratings.\")\n",
    "print(f\"The resulting dataset has {df4.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df4[\"num_reviews\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how much removing ratings outliers affects dataset\n",
    "cutoff = 20000\n",
    "df5 = df4[df4[\"num_reviews\"] <= cutoff]\n",
    "print(f\"There are {df4.shape[0] - df5.shape[0]} books with above {cutoff} reviews.\")\n",
    "print(f\"The resulting dataset has {df5.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how much removing publish_year outliers affects dataset\n",
    "cutoff = 1940\n",
    "df6 = df5[df5[\"publish_year\"] >= cutoff]\n",
    "print(f\"There are {df5.shape[0] - df6.shape[0]} books published before {cutoff}.\")\n",
    "print(f\"The resulting dataset has {df6.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Matrix\n",
    "fig = px.scatter_matrix(df6, dimensions=[\"num_reviews\", \"avg_rating\", \"num_pages\", \"publish_year\"], color=\"in_series\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little more complex scatter, without outliers\n",
    "px.scatter(df6, x=\"publish_year\", y=\"avg_rating\", size=\"num_reviews\", color=\"nonfiction\", range_y=[2.5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Target Practice ðŸŽ¯`fiction`\n",
    "\n",
    "> Binary Classification\n",
    "\n",
    "Is it fiction or is in fuction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the dataset to remove all the extra genre fields\n",
    "genre_cols = [\n",
    "    \"european_literature\",\n",
    "    \"memoir\",\n",
    "    \"fantasy\",\n",
    "    \"religion\",\n",
    "    \"horror\",\n",
    "    \"humor\",\n",
    "    \"historical_fiction\",\n",
    "    \"classics\",\n",
    "    \"adventure\",\n",
    "    \"autobiography\",\n",
    "    \"nonfiction\",\n",
    "    \"novels\",\n",
    "    \"biography\",\n",
    "    \"war\",\n",
    "    \"paranormal\",\n",
    "    \"historical\",\n",
    "    \"thriller\",\n",
    "    \"cultural\",\n",
    "    \"philosophy\",\n",
    "    \"childrens\",\n",
    "    \"literature\",\n",
    "    \"young_adult\",\n",
    "    \"mystery\",\n",
    "    \"science_fiction\",\n",
    "    \"contemporary\",\n",
    "    \"crime\",\n",
    "    \"history\",\n",
    "    \"romance\",\n",
    "    \"all_nonfiction\",\n",
    "    \"overlap\",\n",
    "]\n",
    "\n",
    "df8 = df7.drop(columns=genre_cols)\n",
    "\n",
    "df8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up data into train / test\n",
    "# No validation set because I will be using cross-validation\n",
    "train2, test2 = train_test_split(df8, test_size=0.2, random_state=92)\n",
    "train2.shape, test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new target \"fiction\"\n",
    "target2 = \"fiction\"\n",
    "\n",
    "y2_train = train2[target2]\n",
    "y2_test = test2[target2]\n",
    "y2_train.shape, y2_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Majority Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mode (aka the majoratahhh class)\n",
    "maj_class = y2_train.mode()[0]\n",
    "maj_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions of 100% grass-fed respect-mah-majoritaahhh\n",
    "y2k_pred = [maj_class] * len(y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how we did!!\n",
    "accuracy_score(y2_train, y2k_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...not too shabby.\n",
    "\n",
    "Actually...yes it is. Almost as bad as I could get with binary classification.\n",
    "\n",
    "Just my luck. That's the best I can do.\n",
    "\n",
    "# ðŸ¥º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $JK!$ I can do better.\n",
    "\n",
    "> Starting with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Basic Logistic Baseline\n",
    "\n",
    "_Unit 2, Sprint 1, Module 4_\n",
    "\n",
    "> This time, using a couple features and the `fiction` target!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange X matrices - using X21 to keep numbering organized\n",
    "X21_train = train2.drop(columns=[target2])  # i.e. X 2.1\n",
    "X21_test = test2.drop(columns=[target2])\n",
    "\n",
    "X21_train.shape, X21_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basslinic logistic pipeline\n",
    "pipe21 = make_pipeline(  # i.e. X 2.1\n",
    "    ce.OrdinalEncoder(),\n",
    "    StandardScaler(),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    LogisticRegressionCV(cv=10, n_jobs=-1, random_state=92),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline on the training data\n",
    "pipe21.fit(X21_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the baseline cross-validation accuracy scores\n",
    "scores21 = cross_val_score(pipe21, X21_train, y2_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy scores for the cross-validated logistic model\n",
    "print(\"Accuracy score with simple logistic regression using all features: %0.5f (+/- %0.5f)\" % (scores21.mean(), scores21.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## State of the Patience\n",
    "\n",
    "> ...it pays off!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# ðŸ§© Cont'd in 02-008-04 ðŸ¥³\n",
    "\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
